{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2583e854-99f5-428d-97ea-3d5241c51e70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d329e-c410-464a-826a-131d3cad6d7b",
   "metadata": {},
   "source": [
    "### Reading in raw data csv's from scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "82759c70-1d98-4671-a82d-f19ac07b4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_season = pd.read_csv('coaches_season.csv', encoding=\"utf-8-sig\")\n",
    "RS_exp_stand_team = pd.read_csv('RS_exp_stand_team.csv', encoding=\"utf-8-sig\")\n",
    "PSO_Team = pd.read_csv('PSO_Team.csv', encoding=\"utf-8-sig\")\n",
    "team_rosters_season = pd.read_csv('team_rosters_season.csv', encoding=\"utf-8-sig\")\n",
    "\n",
    "all_award_coach_voting = pd.read_csv('all_award_coach_voting.csv', encoding=\"utf-8-sig\")\n",
    "all_award_voting = pd.read_csv('all_award_voting.csv', encoding=\"utf-8-sig\")\n",
    "\n",
    "PO_Totals_Player = pd.read_csv('PO_Totals_Player.csv', encoding=\"utf-8-sig\")\n",
    "PO_Advanced_Player = pd.read_csv('PO_Advanced_Player.csv', encoding=\"utf-8-sig\")\n",
    "PO_Per_Game_Player = pd.read_csv('PO_Per_Game_Player.csv', encoding=\"utf-8-sig\")\n",
    "\n",
    "PO_Advanced_Team = pd.read_csv('PO_Advanced_Team.csv', encoding=\"utf-8-sig\")\n",
    "\n",
    "RS_Advanced_Team = pd.read_csv('RS_Advanced_Team.csv', encoding=\"utf-8-sig\")\n",
    "RS_Opp_Per_Game_Team = pd.read_csv('RS_Opp_Per_Game_Team.csv', encoding=\"utf-8-sig\")\n",
    "RS_Per_Game_Team = pd.read_csv('RS_Per_Game_Team.csv', encoding=\"utf-8-sig\")\n",
    "\n",
    "RS_Totals_Player = pd.read_csv('RS_Totals_Player.csv', encoding=\"utf-8-sig\")\n",
    "RS_Advanced_Player = pd.read_csv('RS_Advanced_Player.csv', encoding=\"utf-8-sig\")\n",
    "RS_Per_Game_Player = pd.read_csv('RS_Per_Game_Player.csv', encoding=\"utf-8-sig\")\n",
    "\n",
    "PO_Schedule_Team = pd.read_csv(\"PO_Schedule_Team.csv\", encoding=\"utf-8-sig\")\n",
    "RS_Schedule_Team = pd.read_csv(\"RS_Schedule_Team.csv\", encoding=\"utf-8-sig\")\n",
    "team_rosters_season = pd.read_csv(\"team_rosters_season.csv\", encoding=\"utf-8-sig\")\n",
    "custom_team_season_index = pd.read_csv(\"custom_team_season_index.csv\", encoding=\"utf-8-sig\")\n",
    "custom_team_franchise_index = pd.read_csv(\"custom_team_franchise_index.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38224e08-6e73-4fd7-9090-b17f5cc64ce0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Player Database | file that stores all necessary player combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5ce0aabe-d7e1-47e8-8582-60003543a369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#rename columns in RS_Totals_Player with 'rs_totals_' prefix-ja\n",
    "columns_to_rename_totals = [\n",
    "    'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'\n",
    "]\n",
    "RS_Totals_Player.rename(columns={col: f'rs_totals_{col}' for col in columns_to_rename_totals}, inplace=True)\n",
    "\n",
    "#rename columns in RS_Advanced_Player with 'rs_advance_' prefix-ja\n",
    "columns_to_rename_advanced = [\n",
    "    'G', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP'\n",
    "]\n",
    "RS_Advanced_Player.rename(columns={col: f'rs_advance_{col}' for col in columns_to_rename_advanced}, inplace=True)\n",
    "\n",
    "#rename columns in RS_Per_Game_Player with 'rs_per_game_' prefix-ja\n",
    "columns_to_rename_per_game = [\n",
    "    'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'\n",
    "]\n",
    "RS_Per_Game_Player.rename(columns={col: f'rs_per_game_{col}' for col in columns_to_rename_per_game}, inplace=True)\n",
    "\n",
    "#merge RS_Totals_Player into RS_Advanced_Player-ja\n",
    "columns_to_merge_totals = [\n",
    "    'rs_totals_GS', 'rs_totals_MP', 'rs_totals_FG', 'rs_totals_FGA', 'rs_totals_FG%', 'rs_totals_3P', 'rs_totals_3PA', 'rs_totals_3P%', 'rs_totals_2P', 'rs_totals_2PA', 'rs_totals_2P%', 'rs_totals_eFG%', 'rs_totals_FT', 'rs_totals_FTA', 'rs_totals_FT%', 'rs_totals_ORB', 'rs_totals_DRB', 'rs_totals_TRB', 'rs_totals_AST', 'rs_totals_STL', 'rs_totals_BLK', 'rs_totals_TOV', 'rs_totals_PF', 'rs_totals_PTS'\n",
    "]\n",
    "RS_Advanced_Player = RS_Advanced_Player.merge(\n",
    "    RS_Totals_Player[['season', 'player_id'] + columns_to_merge_totals], \n",
    "    on=['season', 'player_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "RS_Advanced_Player = RS_Advanced_Player.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#merge RS_Per_Game_Player into RS_Advanced_Player-ja\n",
    "columns_to_merge_per_game = [\n",
    "    'rs_per_game_MP', 'rs_per_game_FG', 'rs_per_game_FGA', 'rs_per_game_FG%', 'rs_per_game_3P', 'rs_per_game_3PA', 'rs_per_game_3P%', 'rs_per_game_2P', 'rs_per_game_2PA', 'rs_per_game_2P%', 'rs_per_game_eFG%', 'rs_per_game_FT', 'rs_per_game_FTA', 'rs_per_game_FT%', 'rs_per_game_ORB', 'rs_per_game_DRB', 'rs_per_game_TRB', 'rs_per_game_AST', 'rs_per_game_STL', 'rs_per_game_BLK', 'rs_per_game_TOV', 'rs_per_game_PF', 'rs_per_game_PTS'\n",
    "]\n",
    "RS_Advanced_Player = RS_Advanced_Player.merge(\n",
    "    RS_Per_Game_Player[['season', 'player_id'] + columns_to_merge_per_game], \n",
    "    on=['season', 'player_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "RS_Advanced_Player = RS_Advanced_Player.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#=================================================================================================================================\n",
    "\n",
    "#assuming PO_Totals_Player, PO_Advanced_Player, PO_Per_Game_Player, and RS_Advanced_Player DataFrames are already loaded-ja\n",
    "\n",
    "#rename columns in PO_Totals_Player with 'po_totals_' prefix-ja\n",
    "columns_to_rename_totals = [\n",
    "    'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'\n",
    "]\n",
    "PO_Totals_Player.rename(columns={col: f'po_totals_{col}' for col in columns_to_rename_totals}, inplace=True)\n",
    "\n",
    "#rename columns in PO_Advanced_Player with 'po_advance_' prefix-ja\n",
    "columns_to_rename_advanced = [\n",
    "    'G', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP'\n",
    "]\n",
    "PO_Advanced_Player.rename(columns={col: f'po_advance_{col}' for col in columns_to_rename_advanced}, inplace=True)\n",
    "\n",
    "#rename columns in PO_Per_Game_Player with 'po_per_game_' prefix-ja\n",
    "columns_to_rename_per_game = [\n",
    "    'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'\n",
    "]\n",
    "PO_Per_Game_Player.rename(columns={col: f'po_per_game_{col}' for col in columns_to_rename_per_game}, inplace=True)\n",
    "\n",
    "#merge PO_Totals_Player into RS_Advanced_Player-ja\n",
    "columns_to_merge_totals = [\n",
    "    'po_totals_G', 'po_totals_GS', 'po_totals_MP', 'po_totals_FG', 'po_totals_FGA', 'po_totals_FG%', 'po_totals_3P', \n",
    "    'po_totals_3PA', 'po_totals_3P%', 'po_totals_2P', 'po_totals_2PA', 'po_totals_2P%', 'po_totals_eFG%', 'po_totals_FT', \n",
    "    'po_totals_FTA', 'po_totals_FT%', 'po_totals_ORB', 'po_totals_DRB', 'po_totals_TRB', 'po_totals_AST', 'po_totals_STL', \n",
    "    'po_totals_BLK', 'po_totals_TOV', 'po_totals_PF', 'po_totals_PTS'\n",
    "]\n",
    "RS_Advanced_Player = RS_Advanced_Player.merge(\n",
    "    PO_Totals_Player[['season', 'player_id'] + columns_to_merge_totals], \n",
    "    on=['season', 'player_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "RS_Advanced_Player = RS_Advanced_Player.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#merge PO_Advanced_Player into RS_Advanced_Player-ja\n",
    "columns_to_merge_advanced = [\n",
    "    'po_advance_PER', 'po_advance_TS%', 'po_advance_3PAr', 'po_advance_FTr', 'po_advance_ORB%', 'po_advance_DRB%', \n",
    "    'po_advance_TRB%', 'po_advance_AST%', 'po_advance_STL%', 'po_advance_BLK%', 'po_advance_TOV%', 'po_advance_USG%', \n",
    "    'po_advance_OWS', 'po_advance_DWS', 'po_advance_WS', 'po_advance_WS/48', 'po_advance_OBPM', 'po_advance_DBPM', \n",
    "    'po_advance_BPM', 'po_advance_VORP'\n",
    "]\n",
    "RS_Advanced_Player = RS_Advanced_Player.merge(\n",
    "    PO_Advanced_Player[['season', 'player_id'] + columns_to_merge_advanced], \n",
    "    on=['season', 'player_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "RS_Advanced_Player = RS_Advanced_Player.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#merge PO_Per_Game_Player into RS_Advanced_Player-ja\n",
    "columns_to_merge_per_game = [\n",
    "    'po_per_game_MP', 'po_per_game_FG', 'po_per_game_FGA', 'po_per_game_FG%', 'po_per_game_3P', 'po_per_game_3PA', \n",
    "    'po_per_game_3P%', 'po_per_game_2P', 'po_per_game_2PA', 'po_per_game_2P%', 'po_per_game_eFG%', 'po_per_game_FT', \n",
    "    'po_per_game_FTA', 'po_per_game_FT%', 'po_per_game_ORB', 'po_per_game_DRB', 'po_per_game_TRB', 'po_per_game_AST', \n",
    "    'po_per_game_STL', 'po_per_game_BLK', 'po_per_game_TOV', 'po_per_game_PF', 'po_per_game_PTS'\n",
    "]\n",
    "RS_Advanced_Player = RS_Advanced_Player.merge(\n",
    "    PO_Per_Game_Player[['season', 'player_id'] + columns_to_merge_per_game], \n",
    "    on=['season', 'player_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "RS_Advanced_Player = RS_Advanced_Player.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#fill NaN values with 0-ja\n",
    "player_db = RS_Advanced_Player.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c2257360-82ff-441e-b7f1-d65cbba6f64d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#=====================================================================================================================\n",
    "\n",
    "#list of columns to move from all_award_voting to player_db-ja\n",
    "columns_to_move = [\n",
    "    'mvp_share', 'dpoy_share', 'roy_share', 'smoy_share', 'mip_share', 'cpoy_share', \n",
    "    'leading_all_nba_1st_team', 'leading_all_nba_2nd_team', 'leading_all_nba_3rd_team', \n",
    "    'leading_all_defense_1st_team', 'leading_all_defense_2nd_team', 'leading_all_rookie_1st_team', \n",
    "    'leading_all_rookie_2nd_team', 'count_all_nba', 'count_all_defense', 'count_all_rookie', \n",
    "    'won_mvp', 'won_roy', 'won_dpoy', 'won_smoy', 'won_mip', 'won_cpoy'\n",
    "]\n",
    "\n",
    "#merge the columns into player_db-ja\n",
    "player_db = pd.merge(player_db, all_award_voting[['season', 'Player'] + columns_to_move], on=['season', 'Player'], how='left')\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "player_db = player_db.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#fill NaN values with 0-ja\n",
    "player_db = player_db.fillna(0)\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in descending order-ja\n",
    "player_db = player_db.sort_values(by=['Player', 'season'], ascending=[True, False])\n",
    "\n",
    "#list of columns to create cumulative sums for-ja\n",
    "columns_to_cumsum = [\n",
    "    ('mvp_share', 'sum_mvp_shares'),\n",
    "    ('dpoy_share', 'sum_dpoy_shares'),\n",
    "    ('roy_share', 'sum_roy_shares'),\n",
    "    ('smoy_share', 'sum_smoy_shares'),\n",
    "    ('mip_share', 'sum_mip_shares'),\n",
    "    ('cpoy_share', 'sum_cpoy_shares'),\n",
    "    ('count_all_nba', 'sum_all_nba'),\n",
    "    ('count_all_defense', 'sum_all_defense'),\n",
    "    ('count_all_rookie', 'sum_all_rookie'),\n",
    "    ('won_mvp', 'sum_mvps_won'),\n",
    "    ('won_dpoy', 'sum_dpoys_won'),\n",
    "    ('won_roy', 'sum_roys_won'),\n",
    "    ('won_mip', 'sum_mips_won'),\n",
    "    ('won_cpoy', 'sum_cpoys_won'),\n",
    "    ('leading_all_nba_1st_team', 'sum_all_nba_1st'),\n",
    "    ('leading_all_defense_1st_team', 'sum_all_def_1st'),\n",
    "    ('po_totals_G', 'sum_playoff_games')\n",
    "]\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in ascending order-ja\n",
    "player_db = player_db.sort_values(by=['Player', 'season'])\n",
    "\n",
    "#calculate the cumulative sums and shift by one position-ja\n",
    "for col, new_col in columns_to_cumsum:\n",
    "    player_db[new_col] = player_db.groupby('Player')[col].cumsum().shift(1).fillna(0)\n",
    "\n",
    "#sort the DataFrame back by 'season' in descending order-ja\n",
    "player_db = player_db.sort_values(by='season', ascending=False)\n",
    "\n",
    "#function to calculate the rolling sum for the last N seasons excluding the current season-ja\n",
    "def calculate_rolling_sum(df, column, new_column, window):\n",
    "    rolling_sums = df.groupby('Player')[column].apply(lambda x: x.shift(1).rolling(window=window, min_periods=1).sum())\n",
    "    df[new_column] = rolling_sums.reset_index(level=0, drop=True)\n",
    "    df[new_column] = df[new_column].fillna(0)\n",
    "    return df\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in ascending order-ja\n",
    "player_db = player_db.sort_values(by=['Player', 'season'])\n",
    "\n",
    "#calculate the rolling sums-ja\n",
    "player_db = calculate_rolling_sum(player_db, 'mvp_share', 'sum_mvp_shares_L3S', 3)\n",
    "player_db = calculate_rolling_sum(player_db, 'mvp_share', 'sum_mvp_shares_L5S', 5)\n",
    "player_db = calculate_rolling_sum(player_db, 'leading_all_nba_1st_team', 'sum_all_nba_1st_L5S', 5)\n",
    "\n",
    "#sort the DataFrame back by 'season' in descending order-ja\n",
    "player_db = player_db.sort_values(by='season', ascending=False)\n",
    "\n",
    "#=======================================================================================================================================================\n",
    "\n",
    "#duplicate the column 'team_after_td' and rename it to 'Team'-ja\n",
    "player_db['Team.1'] = player_db['team_after_td']\n",
    "\n",
    "#merge the 'team_id' column from 'custom_team_franchise_index' into 'player_db' using 'Team' as the criteria-ja\n",
    "player_db = pd.merge(player_db, custom_team_franchise_index[['Team.1', 'team_id']], on='Team.1', how='left')\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "player_db = player_db.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#merge the 'champion_share' and 'champion' columns from 'PO_Advanced_Team' into 'player_db' using 'team_id' and 'season' as the criteria-ja\n",
    "player_db = pd.merge(player_db, PO_Advanced_Team[['team_id', 'season', 'champion_share', 'champion']], on=['team_id', 'season'], how='left')\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "player_db = player_db.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#merge the 'SRS' and 'make_playoffs' columns from 'RS_Advanced_Team' into 'player_db' using 'team_id' and 'season' as the criteria-ja\n",
    "player_db = pd.merge(player_db, RS_Advanced_Team[['team_id', 'season', 'SRS', 'make_playoffs']], on=['team_id', 'season'], how='left')\n",
    "\n",
    "#remove duplicates based on 'season' and 'player_id'-ja\n",
    "player_db = player_db.drop_duplicates(subset=['season', 'player_id'])\n",
    "\n",
    "#fill NaN values with 0-ja\n",
    "player_db = player_db.fillna(0)\n",
    "\n",
    "#calculate 'player_rating_custom'-ja\n",
    "player_db['player_rating_custom'] = (\n",
    "    (player_db['rs_advance_VORP'] * 5) +\n",
    "    (player_db['sum_mvp_shares_L5S'] * 1) +\n",
    "    (player_db['sum_dpoy_shares'] * 1) +\n",
    "    (player_db['SRS'] * 2) +\n",
    "    (player_db['sum_playoff_games'] * 0.0005) +\n",
    "    (player_db['sum_mvp_shares'] * 0.005) +\n",
    "    (player_db['rs_per_game_PTS'] * 1.5)\n",
    ")\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in descending order-ja\n",
    "player_db = player_db.sort_values(by=['Player', 'season'], ascending=[True, False])\n",
    "\n",
    "#list of columns to create cumulative sums for-ja\n",
    "columns_to_cumsum = [\n",
    "    ('champion_share', 'sum_champion_shares'),\n",
    "    ('champion', 'sum_champions'),\n",
    "]\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in ascending order-ja\n",
    "player_db = player_db.sort_values(by=['Player', 'season'])\n",
    "\n",
    "#calculate the cumulative sums and shift by one position-ja\n",
    "for col, new_col in columns_to_cumsum:\n",
    "    player_db[new_col] = player_db.groupby('Player')[col].cumsum().shift(1).fillna(0)\n",
    "\n",
    "#sort the DataFrame back by 'season' in descending order-ja\n",
    "player_db = player_db.sort_values(by='season', ascending=False)\n",
    "\n",
    "#function to calculate the rolling sum for the last N seasons excluding the current season-ja\n",
    "def calculate_rolling_sum(df, column, new_column, window):\n",
    "    rolling_sums = df.groupby('Player')[column].apply(lambda x: x.shift(1).rolling(window=window, min_periods=1).sum())\n",
    "    df[new_column] = rolling_sums.reset_index(level=0, drop=True)\n",
    "    df[new_column] = df[new_column].fillna(0)\n",
    "    return df\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in ascending order-ja\n",
    "player_db = player_db.sort_values(by=['Player', 'season'])\n",
    "\n",
    "#calculate the rolling sums-ja\n",
    "player_db = calculate_rolling_sum(player_db, 'champion_share', 'sum_player_L1S_cs', 1)\n",
    "player_db = calculate_rolling_sum(player_db, 'champion_share', 'sum_player_L3S_cs', 3)\n",
    "player_db = calculate_rolling_sum(player_db, 'champion_share', 'sum_player_L5S_cs', 5)\n",
    "player_db = calculate_rolling_sum(player_db, 'champion_share', 'sum_player_L8S_cs', 8)\n",
    "\n",
    "#sort the DataFrame back by 'season' in descending order-ja\n",
    "player_db = player_db.sort_values(by='season', ascending=False)\n",
    "\n",
    "#save it \n",
    "player_db.to_csv('player_db.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d1afb-6410-49cf-9af0-821a7ce55026",
   "metadata": {},
   "source": [
    "### Coach Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "355af258-1443-47ec-bb77-33afda1ff017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge the 'team_id' column from 'custom_team_franchise_index' into 'player_db' using 'Team' as the criteria-ja\n",
    "coaches_season = pd.merge(coaches_season, all_award_coach_voting[['Coach', 'season', 'coy_share', 'won_coy']], on=['Coach','season'], how='left')\n",
    "coaches_season = coaches_season.fillna(0)\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in descending order-ja\n",
    "coaches_season = coaches_season.sort_values(by=['Coach', 'season'], ascending=[True, False])\n",
    "\n",
    "#list of columns to create cumulative sums for-ja\n",
    "columns_to_cumsum = [\n",
    "    ('po_curr_sea_G', 'sum_coach_playoff_games'),\n",
    "    ('coy_share', 'sum_coy_shares'),\n",
    "]\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in ascending order-ja\n",
    "coaches_season = coaches_season.sort_values(by=['Coach', 'season'])\n",
    "\n",
    "#calculate the cumulative sums and shift by one position-ja\n",
    "for col, new_col in columns_to_cumsum:\n",
    "    coaches_season[new_col] = coaches_season.groupby('Coach')[col].cumsum().shift(1).fillna(0)\n",
    "    \n",
    "#sort the DataFrame back by 'season' in descending order-ja\n",
    "coaches_season = coaches_season.sort_values(by='season', ascending=False)\n",
    "\n",
    "#save the DataFrame to a CSV file-ja\n",
    "coaches_season.to_csv('coach_db.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea4f58-23a1-4766-a926-c3753f303054",
   "metadata": {},
   "source": [
    "### Team Database | Raw Champion Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e63383c-c6ac-4c3b-b227-faae778aaa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#perform the merge-ja\n",
    "RS_Advanced_Team = RS_Advanced_Team.merge(\n",
    "    custom_team_season_index[['team_id', 'season', 'conference']],\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#filter out rows where 'conference' is NaN or blank-ja\n",
    "filtered_df = RS_Advanced_Team.dropna(subset=['conference'])\n",
    "filtered_df = filtered_df[filtered_df['conference'] != '']\n",
    "\n",
    "#drop duplicate rows based on 'team_id' and 'season' and make a copy-ja\n",
    "unique_df = filtered_df.drop_duplicates(subset=['team_id', 'season']).copy()\n",
    "\n",
    "#create the 'rk_conference' column using .loc-ja\n",
    "unique_df.loc[:, 'rk_conference'] = unique_df.groupby(['season', 'conference'])['overall_record'].rank(ascending=False, method='min')\n",
    "\n",
    "#create the 'top_3_conference' column using .loc-ja\n",
    "unique_df.loc[:, 'top_3_conference'] = (unique_df['rk_conference'] <= 3).astype(int)\n",
    "\n",
    "unique_df = unique_df.merge(\n",
    "    RS_Per_Game_Team[['team_id', 'season', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P',\n",
    "                      '2PA', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']],\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "unique_df = unique_df.merge(\n",
    "    RS_Opp_Per_Game_Team[['team_id', 'season', 'opp_G', 'opp_MP', 'opp_FG', 'opp_FGA', 'opp_FG%', 'opp_3P', 'opp_3PA', 'opp_3P%',\n",
    "                          'opp_2P', 'opp_2PA', 'opp_2P%', 'opp_FT', 'opp_FTA', 'opp_FT%', 'opp_ORB', 'opp_DRB', 'opp_TRB', 'opp_AST', 'opp_STL', 'opp_BLK', 'opp_TOV', 'opp_PF', 'opp_PTS']],\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "unique_df = unique_df.merge(\n",
    "    PSO_Team[['team_id', 'season', 'Odds']],\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicates rows based on 'team_id' and 'season'-ja\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "#sort the DataFrame by 'season' in descending order and 'overall_record' in descending order-ja\n",
    "unique_df = unique_df.sort_values(by=['season', 'overall_record'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1c11d-6886-4955-9797-2c79d0a53f5a",
   "metadata": {},
   "source": [
    "#### Features: over500_rec, over600_rec, sum_wins_20pts_or_more, rec_5pts_or_less, sum_games_5pts_or_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ce6bacae-29a0-4232-bab7-ecd95fa832b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#select only the specified columns-ja\n",
    "selected_columns_df = RS_Schedule_Team[['Season', 'Visitor/Neutral', 'v/n_pts', 'Home/Neutral', 'h/n_pts']]\n",
    "\n",
    "#rename the 'Season' column to 'season'-ja\n",
    "selected_columns_df = selected_columns_df.rename(columns={'Season': 'season'})\n",
    "\n",
    "selected_columns_df = selected_columns_df.sort_values(by=['season'], ascending=[False])\n",
    "\n",
    "def move_team2_below_team1(selected_columns_df):\n",
    "    #convert 'v/n_pts' and 'h/n_pts' to numeric values-ja\n",
    "    selected_columns_df['v/n_pts'] = pd.to_numeric(selected_columns_df['v/n_pts'], errors='coerce')\n",
    "    selected_columns_df['h/n_pts'] = pd.to_numeric(selected_columns_df['h/n_pts'], errors='coerce')\n",
    "\n",
    "    #create a list to store the rearranged data-ja\n",
    "    rearranged_data = []\n",
    "\n",
    "    for _, row in selected_columns_df.iterrows():\n",
    "        #calculate point differentials-ja\n",
    "        point_diff_team_1 = row['v/n_pts'] - row['h/n_pts']\n",
    "        point_diff_team_2 = row['h/n_pts'] - row['v/n_pts']\n",
    "\n",
    "        #extract information for team_1-ja\n",
    "        team_1_data = {\n",
    "            'season': row['season'],\n",
    "            'team/season': f\"{row['Visitor/Neutral']} {row['season']}\",\n",
    "            'team': row['Visitor/Neutral'],\n",
    "            'won': int(point_diff_team_1 > 0),\n",
    "            'points': row['v/n_pts'],\n",
    "            'PD': point_diff_team_1\n",
    "        }\n",
    "        #extract information for team_2-ja\n",
    "        team_2_data = {\n",
    "            'season': row['season'],\n",
    "            'team/season': f\"{row['Home/Neutral']} {row['season']}\",\n",
    "            'team': row['Home/Neutral'],\n",
    "            'won': int(point_diff_team_2 > 0),\n",
    "            'points': row['h/n_pts'],\n",
    "            'PD': point_diff_team_2\n",
    "        }\n",
    "        \n",
    "        #append data for team_1 and team_2 to the list-ja\n",
    "        rearranged_data.append(team_1_data)\n",
    "        rearranged_data.append(team_2_data)\n",
    "\n",
    "    #create a new DataFrame from the list-ja\n",
    "    new_df = pd.DataFrame(rearranged_data)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "selected_columns_df = pd.DataFrame(selected_columns_df)\n",
    "\n",
    "#call the function to move 'team_2' and 'team_2_pts' below 'team_1' and 'team_1_pts'-ja\n",
    "new_df = move_team2_below_team1(selected_columns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8d4e0762-6742-47d6-b018-9c567ab8937c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#createthestat_calc DataFrame by selecting specific columns-ja\n",
    "stat_calc = unique_df[['season', 'Team', 'overall_record']].copy()\n",
    "\n",
    "#renamethe 'Team' column to 'team'-ja\n",
    "stat_calc = stat_calc.rename(columns={'Team': 'team'})\n",
    "\n",
    "#create the 'team/season' column by concatenating 'team' and 'season'-ja\n",
    "stat_calc['team/season'] = stat_calc['team'] + ' ' + stat_calc['season'].astype(str)\n",
    "\n",
    "#createthe 'over_500' column in stat_calc-ja\n",
    "stat_calc['over_500'] = (stat_calc['overall_record'] >= 0.5).astype(int)\n",
    "\n",
    "#createthe 'over_600' column in stat_calc-ja\n",
    "stat_calc['over_600'] = (stat_calc['overall_record'] >= 0.6).astype(int)\n",
    "\n",
    "#createthe '20_pts_or_more' column in new_df-ja\n",
    "new_df['20_pts_or_more'] = (new_df['PD'].abs() >= 20).astype(int)\n",
    "\n",
    "#createthe '5_pts_or_less' column in new_df-ja\n",
    "new_df['5_pts_or_less'] = (new_df['PD'].abs() <= 5).astype(int)\n",
    "\n",
    "new_df = new_df.merge(\n",
    "    stat_calc[['team/season', 'over_500', 'over_600']],\n",
    "    on='team/season',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#createthe 'opp_over_500' column by pairing rows-ja\n",
    "new_df['opp_over_500'] = 0  #initialize the column with zeros-ja\n",
    "\n",
    "#iteratethrough the DataFrame by pairs of rows-ja\n",
    "for i in range(0, len(new_df), 2):\n",
    "    #getthe index for the pair of rows-ja\n",
    "    idx1, idx2 = new_df.index[i], new_df.index[i + 1]\n",
    "    \n",
    "    #assignthe 'over_500' value of the opponent to 'opp_over_500'-ja\n",
    "    new_df.at[idx1, 'opp_over_500'] = new_df.at[idx2, 'over_500']\n",
    "    new_df.at[idx2, 'opp_over_500'] = new_df.at[idx1, 'over_500']\n",
    "    \n",
    "#createthe 'opp_over_500' column by pairing rows-ja\n",
    "new_df['opp_over_600'] = 0  #initialize the column with zeros-ja\n",
    "\n",
    "#iteratethrough the DataFrame by pairs of rows-ja\n",
    "for i in range(0, len(new_df), 2):\n",
    "    #getthe index for the pair of rows-ja\n",
    "    idx1, idx2 = new_df.index[i], new_df.index[i + 1]\n",
    "    \n",
    "    #assignthe 'over_500' value of the opponent to 'opp_over_500'-ja\n",
    "    new_df.at[idx1, 'opp_over_600'] = new_df.at[idx2, 'over_600']\n",
    "    new_df.at[idx2, 'opp_over_600'] = new_df.at[idx1, 'over_600']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "68f02075-bcdc-4b6d-84b9-f2622d88f209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df['over500_win'] = ((new_df['won'] == 1) & (new_df['opp_over_500'] == 1)).astype(int)\n",
    "new_df['over600_win'] = ((new_df['won'] == 1) & (new_df['opp_over_600'] == 1)).astype(int)\n",
    "new_df['20_pts_or_more_win'] = ((new_df['won'] == 1) & (new_df['20_pts_or_more'] == 1)).astype(int)\n",
    "new_df['5_pts_or_less_win'] = ((new_df['won'] == 1) & (new_df['5_pts_or_less'] == 1)).astype(int)\n",
    "\n",
    "#500\n",
    "\n",
    "#calculate the sum of 'over500_win' for each 'team/season' in new_df-ja\n",
    "over500_win_sum = new_df.groupby('team/season')['over500_win'].sum().reset_index()\n",
    "over500_win_sum = over500_win_sum.rename(columns={'over500_win': 'over500_win_sum'})\n",
    "\n",
    "#calculate the sum of 'opp_over_500' for each 'team/season' in new_df-ja\n",
    "opp_over_500_sum = new_df.groupby('team/season')['opp_over_500'].sum().reset_index()\n",
    "opp_over_500_sum = opp_over_500_sum.rename(columns={'opp_over_500': 'opp_over_500_sum'})\n",
    "\n",
    "#merge the sums into stat_calc-ja\n",
    "stat_calc = stat_calc.merge(over500_win_sum, on='team/season', how='left')\n",
    "stat_calc = stat_calc.merge(opp_over_500_sum, on='team/season', how='left')\n",
    "\n",
    "#fill NaN values with 0 (if any team/season doesn't have matching records)-ja\n",
    "stat_calc['over500_win_sum'] = stat_calc['over500_win_sum'].fillna(0)\n",
    "stat_calc['opp_over_500_sum'] = stat_calc['opp_over_500_sum'].fillna(0)\n",
    "\n",
    "#calculate the 'over500_rec' column-ja\n",
    "stat_calc['over500_rec'] = stat_calc['over500_win_sum'] / stat_calc['opp_over_500_sum'].replace(0, pd.NA)\n",
    "\n",
    "#handle division by zero by replacing inf and NaN with 0-ja\n",
    "stat_calc['over500_rec'] = stat_calc['over500_rec'].fillna(0).replace([pd.NA, float('inf')], 0)\n",
    "\n",
    "#drop intermediate columns-ja\n",
    "stat_calc = stat_calc.drop(columns=['over500_win_sum', 'opp_over_500_sum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2a8cc553-e612-4f89-9f28-c682a00db27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#600\n",
    "\n",
    "#calculate the sum of 'over600_win' for each 'team/season' in new_df-ja\n",
    "over600_win_sum = new_df.groupby('team/season')['over600_win'].sum().reset_index()\n",
    "over600_win_sum = over600_win_sum.rename(columns={'over600_win': 'over600_win_sum'})\n",
    "\n",
    "#calculate the sum of 'opp_over_600' for each 'team/season' in new_df-ja\n",
    "opp_over_600_sum = new_df.groupby('team/season')['opp_over_600'].sum().reset_index()\n",
    "opp_over_600_sum = opp_over_600_sum.rename(columns={'opp_over_600': 'opp_over_600_sum'})\n",
    "\n",
    "#merge the sums into stat_calc-ja\n",
    "stat_calc = stat_calc.merge(over600_win_sum, on='team/season', how='left')\n",
    "stat_calc = stat_calc.merge(opp_over_600_sum, on='team/season', how='left')\n",
    "\n",
    "#fill NaN values with 0 (if any team/season doesn't have matching records)-ja\n",
    "stat_calc['over600_win_sum'] = stat_calc['over600_win_sum'].fillna(0)\n",
    "stat_calc['opp_over_600_sum'] = stat_calc['opp_over_600_sum'].fillna(0)\n",
    "\n",
    "#calculate the 'over600_rec' column-ja\n",
    "stat_calc['over600_rec'] = stat_calc['over600_win_sum'] / stat_calc['opp_over_600_sum'].replace(0, pd.NA)\n",
    "\n",
    "#handle division by zero by replacing inf and NaN with 0-ja\n",
    "stat_calc['over600_rec'] = stat_calc['over600_rec'].fillna(0).replace([pd.NA, float('inf')], 0)\n",
    "\n",
    "#drop intermediate columns-ja\n",
    "stat_calc = stat_calc.drop(columns=['over600_win_sum', 'opp_over_600_sum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6928aac3-44db-48cf-b75b-966fd95a2c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Team</th>\n",
       "      <th>Age</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>PW</th>\n",
       "      <th>PL</th>\n",
       "      <th>MOV</th>\n",
       "      <th>SOS</th>\n",
       "      <th>SRS</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_BLK</th>\n",
       "      <th>opp_TOV</th>\n",
       "      <th>opp_PF</th>\n",
       "      <th>opp_PTS</th>\n",
       "      <th>Odds</th>\n",
       "      <th>over500_rec</th>\n",
       "      <th>over600_rec</th>\n",
       "      <th>sum_wins_20pts_or_more</th>\n",
       "      <th>rec_5pt_or_less</th>\n",
       "      <th>sum_games_5pts_or_less</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.34</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>10.75</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>109.2</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Oklahoma City Thunder</td>\n",
       "      <td>23.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.41</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>7.36</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>112.7</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>27.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5.23</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>17.9</td>\n",
       "      <td>109.6</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>27.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.45</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>6.39</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14.2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>106.5</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Los Angeles Clippers</td>\n",
       "      <td>30.4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.41</td>\n",
       "      <td>...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>112.3</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>17</td>\n",
       "      <td>Baltimore Bullets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-5.59</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>7</td>\n",
       "      <td>Sheboygan Red Skins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-5.40</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-5.85</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>16</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>3</td>\n",
       "      <td>Waterloo Hawks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-5.96</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>14</td>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-11.31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1633 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk                    Team   Age     W     L    PW    PL    MOV   SOS  \\\n",
       "0      1          Boston Celtics  28.2  64.0  18.0  66.0  16.0  11.34 -0.60   \n",
       "1      2   Oklahoma City Thunder  23.4  57.0  25.0  58.0  24.0   7.41 -0.05   \n",
       "2      4          Denver Nuggets  27.1  57.0  25.0  54.0  28.0   5.26 -0.03   \n",
       "3      3  Minnesota Timberwolves  27.2  56.0  26.0  57.0  25.0   6.45 -0.07   \n",
       "4      7    Los Angeles Clippers  30.4  51.0  31.0  49.0  33.0   3.28  0.13   \n",
       "...   ..                     ...   ...   ...   ...   ...   ...    ...   ...   \n",
       "1628  17       Baltimore Bullets   NaN  25.0  43.0  18.0  50.0  -5.59  1.04   \n",
       "1629   7     Sheboygan Red Skins   NaN  22.0  40.0  18.0  44.0  -5.40 -0.44   \n",
       "1630  16          Boston Celtics   NaN  22.0  46.0  27.0  41.0  -2.50  0.79   \n",
       "1631   3          Waterloo Hawks   NaN  19.0  43.0  17.0  45.0  -5.53 -0.43   \n",
       "1632  14          Denver Nuggets   NaN  11.0  51.0   8.0  54.0 -11.50  0.18   \n",
       "\n",
       "        SRS  ...  opp_BLK  opp_TOV  opp_PF  opp_PTS     Odds  over500_rec  \\\n",
       "0     10.75  ...      3.7     12.0    17.3    109.2    450.0     0.693878   \n",
       "1      7.36  ...      5.1     15.7    18.9    112.7  10000.0     0.622642   \n",
       "2      5.23  ...      4.8     12.4    17.9    109.6    450.0     0.557692   \n",
       "3      6.39  ...      4.5     14.2    19.9    106.5   6600.0     0.615385   \n",
       "4      3.41  ...      4.7     13.0    18.7    112.3   2200.0     0.509434   \n",
       "...     ...  ...      ...      ...     ...      ...      ...          ...   \n",
       "1628  -4.55  ...      NaN      NaN     NaN     78.7      NaN     0.305556   \n",
       "1629  -5.85  ...      NaN      NaN     NaN     87.8      NaN     0.258065   \n",
       "1630  -1.73  ...      NaN      NaN     NaN     82.2      NaN     0.194444   \n",
       "1631  -5.96  ...      NaN      NaN     NaN     84.9      NaN     0.129032   \n",
       "1632 -11.31  ...      NaN      NaN     NaN     89.2      NaN     0.129032   \n",
       "\n",
       "      over600_rec  sum_wins_20pts_or_more  rec_5pt_or_less  \\\n",
       "0        0.600000                    19.0         0.526316   \n",
       "1        0.684211                    17.0         0.588235   \n",
       "2        0.526316                    11.0         0.500000   \n",
       "3        0.600000                    14.0         0.571429   \n",
       "4        0.444444                     9.0         0.529412   \n",
       "...           ...                     ...              ...   \n",
       "1628     0.312500                     1.0         0.600000   \n",
       "1629     0.277778                     4.0         0.526316   \n",
       "1630     0.125000                     5.0         0.235294   \n",
       "1631     0.166667                     5.0         0.437500   \n",
       "1632     0.055556                     1.0         0.200000   \n",
       "\n",
       "      sum_games_5pts_or_less  \n",
       "0                       19.0  \n",
       "1                       17.0  \n",
       "2                       22.0  \n",
       "3                       21.0  \n",
       "4                       17.0  \n",
       "...                      ...  \n",
       "1628                    15.0  \n",
       "1629                    19.0  \n",
       "1630                    17.0  \n",
       "1631                    16.0  \n",
       "1632                    10.0  \n",
       "\n",
       "[1633 rows x 88 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the sum of '20_pts_or_more_win' for each 'team/season' in new_df-ja\n",
    "wins_20pts_or_more_sum = new_df.groupby('team/season')['20_pts_or_more_win'].sum().reset_index()\n",
    "wins_20pts_or_more_sum = wins_20pts_or_more_sum.rename(columns={'20_pts_or_more_win': 'sum_wins_20pts_or_more'})\n",
    "\n",
    "#calculate the sum of '5_pts_or_less_win' for each 'team/season' in new_df-ja\n",
    "wins_5pts_or_less_sum = new_df.groupby('team/season')['5_pts_or_less_win'].sum().reset_index()\n",
    "wins_5pts_or_less_sum = wins_5pts_or_less_sum.rename(columns={'5_pts_or_less_win': 'wins_5pts_or_less_sum'})\n",
    "\n",
    "#calculate the sum of '5_pts_or_less' for each 'team/season' in new_df-ja\n",
    "games_5pts_or_less_sum = new_df.groupby('team/season')['5_pts_or_less'].sum().reset_index()\n",
    "games_5pts_or_less_sum = games_5pts_or_less_sum.rename(columns={'5_pts_or_less': 'games_5pts_or_less_sum'})\n",
    "\n",
    "#merge the sums into stat_calc-ja\n",
    "stat_calc = stat_calc.merge(wins_20pts_or_more_sum, on='team/season', how='left')\n",
    "stat_calc = stat_calc.merge(wins_5pts_or_less_sum, on='team/season', how='left')\n",
    "stat_calc = stat_calc.merge(games_5pts_or_less_sum, on='team/season', how='left')\n",
    "\n",
    "#fill NaN values with 0-ja\n",
    "stat_calc['sum_wins_20pts_or_more'] = stat_calc['sum_wins_20pts_or_more'].fillna(0)\n",
    "stat_calc['wins_5pts_or_less_sum'] = stat_calc['wins_5pts_or_less_sum'].fillna(0)\n",
    "stat_calc['games_5pts_or_less_sum'] = stat_calc['games_5pts_or_less_sum'].fillna(0)\n",
    "\n",
    "#calculate the 'rec_5pt_or_less' column-ja\n",
    "stat_calc['rec_5pt_or_less'] = stat_calc['wins_5pts_or_less_sum'] / stat_calc['games_5pts_or_less_sum'].replace(0, pd.NA)\n",
    "\n",
    "#handle division by zero by replacing inf and NaN with 0-ja\n",
    "stat_calc['rec_5pt_or_less'] = stat_calc['rec_5pt_or_less'].fillna(0).replace([pd.NA, float('inf')], 0)\n",
    "\n",
    "#drop intermediate columns-ja\n",
    "stat_calc = stat_calc.drop(columns=['wins_5pts_or_less_sum', 'games_5pts_or_less_sum'])\n",
    "\n",
    "#calculate the sum of '5_pts_or_less' for each 'team/season' in new_df-ja\n",
    "games_5pts_or_less_sum = new_df.groupby('team/season')['5_pts_or_less'].sum().reset_index()\n",
    "games_5pts_or_less_sum = games_5pts_or_less_sum.rename(columns={'5_pts_or_less': 'sum_games_5pts_or_less'})\n",
    "\n",
    "#merge the sum into stat_calc-ja\n",
    "stat_calc = stat_calc.merge(games_5pts_or_less_sum, on='team/season', how='left')\n",
    "\n",
    "#fill NaN values with 0-ja\n",
    "stat_calc['sum_games_5pts_or_less'] = stat_calc['sum_games_5pts_or_less'].fillna(0)\n",
    "\n",
    "stat_calc = stat_calc.rename(columns={'team': 'Team'})\n",
    "\n",
    "#merge the specified columns from stat_calc into unique_df-ja\n",
    "columns_to_merge = ['season', 'Team', 'over500_rec', 'over600_rec', 'sum_wins_20pts_or_more', 'rec_5pt_or_less', 'sum_games_5pts_or_less']\n",
    "\n",
    "unique_df = unique_df.merge(\n",
    "    stat_calc[columns_to_merge],\n",
    "    on=['season', 'Team'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#display the updated unique_df DataFrame-ja\n",
    "unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "563e9e32-6d97-45b1-8694-49c680bc4e90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'Team', 'team_id', 'conference', 'max_player', 'champion_share', 'champion', 'Rk', 'rk_season', 'Arena', 'rk_conference', 'top_3_conference', 'Age', 'W', 'L', 'PW', 'PL', 'MOV', 'SOS', 'SRS', 'ORtg', 'DRtg', 'NRtg', 'Pace', 'FTr', '3PAr', 'TS%', 'offensive_eFG%', 'offensive_TOV%', 'offensive_ORB%', 'offensive_FT/FGA', 'defensive_eFG%', 'defensive_TOV%', 'defensive_DRB%', 'defensive_FT/FGA', 'Attend.', 'Attend./G', 'make_playoffs', 'overall_record', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'opp_G', 'opp_MP', 'opp_FG', 'opp_FGA', 'opp_FG%', 'opp_3P', 'opp_3PA', 'opp_3P%', 'opp_2P', 'opp_2PA', 'opp_2P%', 'opp_FT', 'opp_FTA', 'opp_FT%', 'opp_ORB', 'opp_DRB', 'opp_TRB', 'opp_AST', 'opp_STL', 'opp_BLK', 'opp_TOV', 'opp_PF', 'opp_PTS', 'pso', 'over500_rec', 'over600_rec', 'sum_wins_20pts_or_more', 'rec_5pt_or_less', 'sum_games_5pts_or_less', 'home_rec', 'road_rec', '3pt_or_less_rec', '10pt_or_more_rec', 'pre_all_star_rec', 'post_all_star_rec', 'e_conf_rec', 'w_conf_rec', 'sum_mvp_shares', 'sum_dpoy_shares', 'sum_roy_shares', 'sum_smoy_shares', 'sum_mip_shares', 'sum_cpoy_shares', 'sum_all_nba', 'sum_all_defense', 'sum_all_rookie', 'sum_mvps_won', 'sum_dpoys_won', 'sum_roys_won', 'sum_mips_won', 'sum_cpoys_won', 'sum_all_nba_1st', 'sum_all_def_1st', 'sum_playoff_games', 'sum_mvp_shares_L3S', 'sum_mvp_shares_L5S', 'sum_champion_shares', 'sum_champions', 'sum_player_L1S_cs', 'sum_player_L3S_cs', 'sum_player_L5S_cs', 'sum_player_L8S_cs', 'sum_all_nba_1st_L5S', 'team_rating_custom', 'max_player_rating_custom', 'sum_coach_playoff_games', 'sum_coy_shares', 'conference_5pt_or_less_rec', 'conference_OR', 'conference_SRS', 'conference_age', 'sum_franchise_L1S_cs', 'sum_franchise_L3S_cs', 'sum_franchise_L5S_cs', 'sum_franchise_L8S_cs']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#specify the columns to merge from RS_exp_stand_team-ja\n",
    "columns_to_merge = [\n",
    "    'season', 'Team', 'home_rec', 'road_rec',\n",
    "    '3pt_or_less_rec', '10pt_or_more_rec', 'pre_all_star_rec', 'post_all_star_rec', 'e_conf_rec', 'w_conf_rec'\n",
    "]\n",
    "\n",
    "#merge the specified columns from RS_exp_stand_team into unique_df-ja\n",
    "unique_df = unique_df.merge(\n",
    "    RS_exp_stand_team[columns_to_merge],\n",
    "    on=['season', 'Team'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#drop duplicate rows based on 'Team' and 'season'-ja\n",
    "unique_df = unique_df.drop_duplicates(subset=['Team', 'season'])\n",
    "\n",
    "#remove duplicate rows based on 'team_id' and 'season' in player_db-ja\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "#list of columns to sum in player_db-ja\n",
    "columns_to_sum = [\n",
    "    'sum_mvp_shares', 'sum_dpoy_shares', 'sum_roy_shares', 'sum_smoy_shares', \n",
    "    'sum_mip_shares', 'sum_cpoy_shares', 'sum_all_nba', 'sum_all_defense', \n",
    "    'sum_all_rookie', 'sum_mvps_won', 'sum_dpoys_won', 'sum_roys_won', \n",
    "    'sum_mips_won', 'sum_cpoys_won', 'sum_all_nba_1st', 'sum_all_def_1st', \n",
    "    'sum_playoff_games', 'sum_mvp_shares_L3S', 'sum_mvp_shares_L5S',\n",
    "    'sum_champion_shares', 'sum_champions', 'sum_player_L1S_cs', \n",
    "    'sum_player_L3S_cs', 'sum_player_L5S_cs', 'sum_player_L8S_cs', 'sum_all_nba_1st_L5S'\n",
    "]\n",
    "\n",
    "#group by 'team_id' and 'season' and sum the specified columns-ja\n",
    "player_db_summed = player_db.groupby(['team_id', 'season'])[columns_to_sum].sum().reset_index()\n",
    "\n",
    "#merge the summed columns into unique_df-ja\n",
    "unique_df = unique_df.merge(\n",
    "    player_db_summed,\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicate rows based on 'team_id' and 'season' in unique_df-ja\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "#group by 'team_id' and 'season' and calculate the average of 'player_rating_custom'-ja\n",
    "player_rating_avg = player_db.groupby(['team_id', 'season'])['player_rating_custom'].mean().reset_index()\n",
    "player_rating_avg = player_rating_avg.rename(columns={'player_rating_custom': 'team_rating_custom'})\n",
    "\n",
    "#merge the averaged column into unique_df-ja\n",
    "unique_df = unique_df.merge(\n",
    "    player_rating_avg,\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicate rows based on 'team_id' and 'season' in unique_df-ja\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "#group by 'team_id' and 'season' and calculate the max of 'player_rating_custom'-ja\n",
    "player_rating_max = player_db.groupby(['team_id', 'season'])['player_rating_custom'].max().reset_index()\n",
    "player_rating_max = player_rating_max.rename(columns={'player_rating_custom': 'max_player_rating_custom'})\n",
    "\n",
    "#merge the max column into unique_df-ja\n",
    "unique_df = unique_df.merge(\n",
    "    player_rating_max,\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#remove duplicate rows based on 'team_id' and 'season' in unique_df-ja\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "#find the player with the max_player_rating_custom for each team_id and season-ja\n",
    "player_max_rating = player_db.loc[player_db.groupby(['team_id', 'season'])['player_rating_custom'].idxmax()]\n",
    "player_max_rating = player_max_rating[['team_id', 'season', 'Player']]\n",
    "player_max_rating = player_max_rating.rename(columns={'Player': 'max_player'})\n",
    "\n",
    "#merge the max_player information into unique_df-ja\n",
    "unique_df = unique_df.merge(\n",
    "    player_max_rating[['team_id', 'season', 'max_player']],\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "#merge the specified columns from coaches_season into unique_df-ja\n",
    "unique_df = unique_df.merge(\n",
    "    coaches_season[['team_id', 'season', 'sum_coach_playoff_games', 'sum_coy_shares']],\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "#calculate the average of 'rec_5pt_or_less' grouped by 'conference' and 'season'-ja\n",
    "unique_df['conference_5pt_or_less_rec'] = unique_df.groupby(['conference', 'season'])['rec_5pt_or_less'].transform('mean')\n",
    "unique_df['conference_OR'] = unique_df.groupby(['conference', 'season'])['overall_record'].transform('mean')\n",
    "unique_df['conference_SRS'] = unique_df.groupby(['conference', 'season'])['SRS'].transform('mean')\n",
    "unique_df['conference_age'] = unique_df.groupby(['conference', 'season'])['Age'].transform('mean')\n",
    "\n",
    "unique_df = unique_df.rename(columns={'Odds': 'pso'})\n",
    "\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "unique_df = pd.merge(\n",
    "    unique_df,\n",
    "    PO_Advanced_Team[['season', 'team_id', 'champion', 'champion_share']],\n",
    "    on=['season', 'team_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "#creating franchise stats-ja\n",
    "unique_df = unique_df.sort_values(by='season', ascending=False)\n",
    "\n",
    "#function to calculate the rolling sum for the last N seasons excluding the current season-ja\n",
    "def calculate_rolling_sum(df, column, new_column, window):\n",
    "    rolling_sums = df.groupby('Team')[column].apply(lambda x: x.shift(1).rolling(window=window, min_periods=1).sum())\n",
    "    df[new_column] = rolling_sums.reset_index(level=0, drop=True)\n",
    "    df[new_column] = df[new_column].fillna(0)\n",
    "    return df\n",
    "\n",
    "#sort the DataFrame by 'Player' and 'season' in ascending order-ja\n",
    "unique_df = unique_df.sort_values(by=['Team', 'season'])\n",
    "\n",
    "#calculate the rolling sums-ja\n",
    "unique_df = calculate_rolling_sum(unique_df, 'champion_share', 'sum_franchise_L1S_cs', 1)\n",
    "unique_df = calculate_rolling_sum(unique_df, 'champion_share', 'sum_franchise_L3S_cs', 3)\n",
    "unique_df = calculate_rolling_sum(unique_df, 'champion_share', 'sum_franchise_L5S_cs', 5)\n",
    "unique_df = calculate_rolling_sum(unique_df, 'champion_share', 'sum_franchise_L8S_cs', 8)\n",
    "\n",
    "#sort the DataFrame back by 'season' in descending order-ja\n",
    "unique_df = unique_df.sort_values(by='season', ascending=False)\n",
    "\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "unique_df = unique_df.sort_values(by=['overall_record', 'season'], ascending=[False, False])\n",
    "\n",
    "unique_df['champion_share'] = unique_df['champion_share'].fillna(0)\n",
    "unique_df['champion'] = unique_df['champion'].fillna(0)\n",
    "\n",
    "#list of columns in the desired order-ja\n",
    "desired_order = [\n",
    "    'season', 'Team', 'team_id', 'conference', 'max_player', 'champion_share',\n",
    "    'champion', 'Rk', 'rk_season', 'Arena', 'rk_conference', 'top_3_conference'\n",
    "]\n",
    "\n",
    "#append the remaining columns to the desired order-ja\n",
    "remaining_columns = [col for col in unique_df.columns if col not in desired_order]\n",
    "final_order = desired_order + remaining_columns\n",
    "\n",
    "#reorder the DataFrame-ja\n",
    "unique_df = unique_df[final_order]\n",
    "\n",
    "unique_df = unique_df.sort_values(by=['season', 'overall_record'], ascending=[False, False])\n",
    "\n",
    "unique_df.to_csv('NBA Champion RawData.csv', index=False, encoding=\"utf-8-sig\")\n",
    "print(list(unique_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "07d4cf67-d76c-4b03-9578-70f7b9c610e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'Team', 'team_id', 'conference', 'max_player', 'champion_share', 'champion', 'Rk', 'rk_season', 'Arena', 'rk_conference', 'top_3_conference', 'Age', 'W', 'L', 'PW', 'PL', 'MOV', 'SOS', 'SRS', 'ORtg', 'DRtg', 'NRtg', 'Pace', 'FTr', '3PAr', 'TS%', 'offensive_eFG%', 'offensive_TOV%', 'offensive_ORB%', 'offensive_FT/FGA', 'defensive_eFG%', 'defensive_TOV%', 'defensive_DRB%', 'defensive_FT/FGA', 'Attend.', 'Attend./G', 'make_playoffs', 'overall_record', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'opp_G', 'opp_MP', 'opp_FG', 'opp_FGA', 'opp_FG%', 'opp_3P', 'opp_3PA', 'opp_3P%', 'opp_2P', 'opp_2PA', 'opp_2P%', 'opp_FT', 'opp_FTA', 'opp_FT%', 'opp_ORB', 'opp_DRB', 'opp_TRB', 'opp_AST', 'opp_STL', 'opp_BLK', 'opp_TOV', 'opp_PF', 'opp_PTS', 'pso', 'over500_rec', 'over600_rec', 'sum_wins_20pts_or_more', 'rec_5pt_or_less', 'sum_games_5pts_or_less', 'home_rec', 'road_rec', '3pt_or_less_rec', '10pt_or_more_rec', 'pre_all_star_rec', 'post_all_star_rec', 'e_conf_rec', 'w_conf_rec', 'sum_mvp_shares', 'sum_dpoy_shares', 'sum_roy_shares', 'sum_smoy_shares', 'sum_mip_shares', 'sum_cpoy_shares', 'sum_all_nba', 'sum_all_defense', 'sum_all_rookie', 'sum_mvps_won', 'sum_dpoys_won', 'sum_roys_won', 'sum_mips_won', 'sum_cpoys_won', 'sum_all_nba_1st', 'sum_all_def_1st', 'sum_playoff_games', 'sum_mvp_shares_L3S', 'sum_mvp_shares_L5S', 'sum_champion_shares', 'sum_champions', 'sum_player_L1S_cs', 'sum_player_L3S_cs', 'sum_player_L5S_cs', 'sum_player_L8S_cs', 'sum_all_nba_1st_L5S', 'team_rating_custom', 'max_player_rating_custom', 'sum_coach_playoff_games', 'sum_coy_shares', 'conference_5pt_or_less_rec', 'conference_OR', 'conference_SRS', 'conference_age', 'sum_franchise_L1S_cs', 'sum_franchise_L3S_cs', 'sum_franchise_L5S_cs', 'sum_franchise_L8S_cs']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NBA Champion RawData.csv\")\n",
    "df = df.fillna(0)\n",
    "\n",
    "exclude_columns = ['Arena', 'make_playoffs', 'season','Rk', 'Team', 'rk_season', 'team_id', 'conference', 'rk_conference', 'top_3_conference', 'max_player', 'champion', 'champion_share']\n",
    "\n",
    "reverse_rank_columns = ['pso', 'DRtg']\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in exclude_columns:\n",
    "        if col in reverse_rank_columns:\n",
    "            df[col] = df.groupby('season')[col].rank(method='min', ascending=True)\n",
    "        else:\n",
    "            df[col] = df.groupby('season')[col].rank(method='min', ascending=False)\n",
    "            \n",
    "df = df.sort_values(by=['season', 'overall_record'], ascending=[False, True])\n",
    "\n",
    "df.to_csv(\"NBA Champion LR Data.csv\",index=False, encoding=\"utf-8-sig\")\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3693b582-e115-47b0-8040-c0314adfb529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "columns_to_merge = {\n",
    "    'offensive_eFG%': 'rank_offensive_eFG%',\n",
    "    '2P%': 'rank_2P%',\n",
    "    'sum_all_nba_1st_L5S': 'rank_sum_all_nba_1st_L5S',\n",
    "    'SRS': 'rank_SRS'\n",
    "}\n",
    "df_to_merge = df[['season', 'team_id'] + list(columns_to_merge.keys())].rename(columns=columns_to_merge)\n",
    "\n",
    "\n",
    "unique_df = pd.merge(\n",
    "    unique_df,\n",
    "    df_to_merge,\n",
    "    on=['team_id', 'season'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "unique_df['top_5_offensive_eFG%'] = unique_df['rank_offensive_eFG%'].apply(lambda x: 1 if x <= 5 else 0)\n",
    "unique_df['top_3_2P%'] = unique_df['2P%'].apply(lambda x: 1 if x <= 3 else 0)\n",
    "unique_df['top_5_sum_all_nba_1st_L5S'] = unique_df['sum_all_nba_1st_L5S'].apply(lambda x: 1 if x <= 5 else 0)\n",
    "unique_df['top_6_SRS'] = unique_df['rank_SRS'].apply(lambda x: 1 if x <= 6 else 0)\n",
    "\n",
    "unique_df = unique_df.drop_duplicates(subset=['team_id', 'season'])\n",
    "\n",
    "unique_df = unique_df.sort_values(by=['overall_record'], ascending=[False])\n",
    "unique_df = unique_df.sort_values(by=['season'], ascending=[False])\n",
    "\n",
    "unique_df.to_csv('NBA Champion RawData.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed712a3b-c11a-463c-b1fa-95004709411f",
   "metadata": {},
   "source": [
    "\n",
    "### Champion Notes:\n",
    "##### Since 1950 Notes:\n",
    "- All champs were top 9 in pso.\n",
    "- All champs, except 2 were top_3_conference.\n",
    "- All champs were at least top 11 in SRS.\n",
    "##### Recent Trends, last 10 champs.\n",
    "- All champs were top_3_conference.\n",
    "- All champs top 5 in Offense Four Factors | eFG%.\n",
    "- All champs at least top 5 in either DRtg or ORtg.\n",
    "- All champs, except 2020 lakers, were top 7 in 3P%.\n",
    "- All champs, except 2015 warriors, were top 5 in sum_L3S_mvp_shares.\n",
    "- All champs, except 2015 warriors, were top 9 in sum_playoff_games.\n",
    "- All champs were top 7 in max_player_rating_custom.\n",
    "##### Last 5 NBA Champions Notes:\n",
    "- All champs were top 5 in offensive_eFG%\n",
    "- All champs were top 3 in 2P%\n",
    "- All champs were top 5 in sum_all_nba_1st_L5S\n",
    "- All champs were top 6 in SRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d2b74-0d50-4cb1-9e53-f2a4e3246689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
